{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4716adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file if it exists\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.schema import Document\n",
    "import re\n",
    "from typing import List, TypedDict\n",
    "\n",
    "class CustomMarkdownLoader(BaseLoader):\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        with open(self.file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "       # Extract frontmatter if it exists\n",
    "        frontmatter_match = re.match(r'^---\\n(.*?)\\n---\\n(.*)', content, re.DOTALL)\n",
    "        \n",
    "        if frontmatter_match:\n",
    "            frontmatter = frontmatter_match.group(1)\n",
    "            content_body = frontmatter_match.group(2)\n",
    "            \n",
    "            # Parse frontmatter into a dictionary\n",
    "            metadata = {}\n",
    "            for line in frontmatter.split('\\n'):\n",
    "                if ':' in line:\n",
    "                    key, value = line.split(':', 1)\n",
    "                    metadata[key.strip()] = value.strip()\n",
    "            \n",
    "            # Add source metadata\n",
    "            metadata['source'] = os.path.basename(self.file_path)\n",
    "            \n",
    "            return [Document(page_content=content_body.strip(), metadata=metadata)]\n",
    "        else:\n",
    "            return [Document(page_content=content, metadata={'source': os.path.basename(self.file_path)})]\n",
    "\n",
    "\n",
    "documents = []\n",
    "for filename in os.listdir(\"./../data/translated/\"):\n",
    "    if filename.endswith('.md'):\n",
    "        loader = CustomMarkdownLoader(os.path.join(\"./../data/translated/\", filename))\n",
    "        documents.extend(loader.load())\n",
    "print(f\"Loaded {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f463f70",
   "metadata": {},
   "outputs": [],
   "source": "from langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_openai import ChatOpenAI\nfrom langchain.prompts import PromptTemplate\n\n# Text splitting \ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=800,\n    chunk_overlap=100,\n    length_function=len,\n)\n\nchunks = text_splitter.split_documents(documents)\n\n# Create vector store \nembeddings = OpenAIEmbeddings()\nvectorstore = Chroma.from_documents(\n    documents=chunks,\n    embedding=embeddings,\n    persist_directory=\"./livre_db\"\n)\n\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88101d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an expert assistant for exploring a book. Based on the provided excerpts, answer the question precisely.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Quote relevant passages in quotation marks\n",
    "- Indicate source chapter: (Chapter: \"title\")\n",
    "- If info isn't in excerpts, say so clearly\n",
    "- Synthesize if multiple excerpts address the topic\n",
    "\n",
    "BOOK EXCERPTS:\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "STRUCTURED RESPONSE:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vectorstore.similarity_search(state[\"question\"], k= 20)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def answer(state: State):\n",
    "    prompt = PROMPT.format(context=\"\\n\\n\".join([doc.page_content for doc in state[\"context\"]]), question=state[\"question\"])\n",
    "    response = llm(prompt)\n",
    "    return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f914dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, answer])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ebdd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": \"Who is Shirone?\"})\n",
    "\n",
    "print(f\"Context: {len(result['context'])}\\n\\n\")\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106ce5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}